{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "pip install ollama\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: ollama in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (0.4.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from ollama) (2.10.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.2.2)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T15:02:44.149935Z",
     "iopub.status.busy": "2024-11-28T15:02:44.149036Z",
     "iopub.status.idle": "2024-11-28T15:02:46.988655Z",
     "shell.execute_reply": "2024-11-28T15:02:46.987904Z",
     "shell.execute_reply.started": "2024-11-28T15:02:44.149875Z"
    },
    "trusted": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load input file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "project_title_map = {\n",
    "        \"archives_space\": \"Archives Space Project\",\n",
    "        \"archives_space_old\": \"Archives Space Project\",\n",
    "        \"neurohub\": \"NeuroHub Project\",\n",
    "        \"open_spending\": \"Open Spending Project\",\n",
    "        \"open_spending_old\": \"Open Spending Project\",\n",
    "        \"planning_poker\": \"Planning Poker Project\",\n",
    "        \"recycling\": \"Recycling Project\",\n",
    "        \"color_ide\": \"ColorIDE Project\"\n",
    "    }\n",
    "projects = [\"archives_space\", \"neurohub\", \"open_spending\", \"planning_poker\", \"recycling\", \"color_ide\"]\n",
    "\n",
    "selected_project = projects[5] # select which project you want to test with\n",
    "\n",
    "project_path = \"./input_files/user_stories_{}.json\".format(selected_project)\n",
    "with open(project_path, 'r') as file:\n",
    "        project_content = file.read()\n",
    "        project_title = project_title_map[selected_project]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load model and configure model parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "\n",
    "#model_version = \"llama3.1:8b-instruct-fp16\"\n",
    "model_version = \"llama3.1:70b\"\n",
    "num_ctx = 10240 #context window higher because of the refinement process\n",
    "temperature = 0 # should be kept low for deterministic results, default value 0.8\n",
    "num_predict = 1 # we only want 1 token, the score for the given architecture pattern\n",
    "\n",
    "options = {\"num_ctx\": num_ctx, \"temperature\": temperature, \"num_predict\": 1000}\n",
    "#model_name = \"emir_\" + model_version\n",
    "model_name = model_version\n",
    "#ollama.create(model=model_name, modelfile=modelfile)\n",
    "\n",
    "one_shot = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get first assessment from model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "client = Client(headers={})\n",
    "\n",
    "def get_architecture_score(project_title, project_content, architecture_pattern, model_name, options):\n",
    "    generator_system_message = {'role': 'system', 'content': \"\"\"\n",
    "    You are a software architect. Your job is to get a list of categorized user stories with a description, analyze them in detail and\n",
    "    assign a score for the given architecture pattern depending on their relevance to the project and \n",
    "    if it would prove useful in the implementation of the described project.\n",
    "    IMPORTANT: You MUST respond with ONLY a single digit from 1 to 5, representing the score. DO NOT provide any other text, explanation, introduction or formatting.\n",
    "    IMPORTANT: The user stories are categorized and given in json format, analyze them really carefully before you answer.\n",
    "    IMPORTANT: Your answer must relate to the suitability of the given software architecture pattern to the described project.\n",
    "\n",
    "    EXAMPLE 1:\n",
    "\n",
    "    Project Title: <title>\n",
    "\n",
    "    User Stories:\n",
    "\n",
    "    <user stories>\n",
    "\n",
    "    Architecture Pattern: Layered Architecture\n",
    "\n",
    "    Score: <int>\n",
    "\n",
    "    EXAMPLE 2:\n",
    "\n",
    "    Project Title: <title>\n",
    "\n",
    "    User Stories:\n",
    "\n",
    "    <user stories>\n",
    "\n",
    "    Architecture Pattern: Microservices Architecture\n",
    "\n",
    "    Score: <int>\n",
    "    \"\"\"}\n",
    "    user_message = {'role': 'user', 'content': f\"\"\"\n",
    "    Project Title: {project_title}\n",
    "\n",
    "    User Stories:\n",
    "\n",
    "    {project_content}\n",
    "\n",
    "    Architecture Pattern: {architecture_pattern}\n",
    "\n",
    "    Score: \n",
    "    \"\"\"}\n",
    "    messages = [generator_system_message, user_message]  # Reset messages for each pattern\n",
    "\n",
    "    response = client.chat(model=model_name, messages=messages, options=options)\n",
    "    message = response['message']\n",
    "    print(message['content'])\n",
    "\n",
    "    try:\n",
    "        score = int(message['content'].strip())\n",
    "        if 1 <= score <= 5:\n",
    "            return score\n",
    "        else:\n",
    "            print(f\"Invalid score: {score}. Model returned a number outside the range 1-5.\")\n",
    "            return None  # Or raise an exception\n",
    "    except ValueError:\n",
    "        print(f\"Invalid response: '{message['content']}'. Model did not return a valid integer.\")\n",
    "        return None  # Or raise an exception"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "architecture_patterns = [\"Layered Architecture\", \"Event-Driven Architecture (Pub-Sub Architecture)\",\n",
    " \"Microkernel Architecture\", \"Microservices Architecture\", \"Space-Based Architecture\", \"Pipeline Architecture (Pipe-Filter Architecture)\", \"Client-Server Architecture\"]\n",
    "\n",
    "for pattern in architecture_patterns:\n",
    "    score = get_architecture_score(project_title, project_content, pattern, model_name, options)\n",
    "    if score is not None:\n",
    "        print(f\"Score for {pattern}: {score}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n",
      "Score for Layered Architecture: 4\n",
      "4\n",
      "Score for Event-Driven Architecture (Pub-Sub Architecture): 4\n",
      "4\n",
      "Score for Microkernel Architecture: 4\n",
      "4\n",
      "Score for Microservices Architecture: 4\n",
      "4\n",
      "Score for Space-Based Architecture: 4\n",
      "4\n",
      "Score for Pipeline Architecture (Pipe-Filter Architecture): 4\n",
      "4\n",
      "Score for Client-Server Architecture: 4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "interpreter": {
   "hash": "95ec9ec1504d83f612128e0fb229072f90bbb4cb09d9d5d93b5dd26e0ca2cfd1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
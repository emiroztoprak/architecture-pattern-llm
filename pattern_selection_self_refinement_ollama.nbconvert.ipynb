{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:40:42.750761Z",
     "iopub.status.busy": "2025-02-07T12:40:42.749841Z",
     "iopub.status.idle": "2025-02-07T12:40:43.958863Z",
     "shell.execute_reply": "2025-02-07T12:40:43.958196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (0.4.2)\r\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from ollama) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from ollama) (2.10.2)\r\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.3.0)\r\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2.10)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\r\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.2.2)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:40:43.961285Z",
     "iopub.status.busy": "2025-02-07T12:40:43.961090Z",
     "iopub.status.idle": "2025-02-07T12:40:43.972300Z",
     "shell.execute_reply": "2025-02-07T12:40:43.969690Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_title_map = {\n",
    "        \"archives_space\": \"Archives Space Project\",\n",
    "        \"archives_space_old\": \"Archives Space Project\",\n",
    "        \"neurohub\": \"NeuroHub Project\",\n",
    "        \"open_spending\": \"Open Spending Project\",\n",
    "        \"open_spending_old\": \"Open Spending Project\",\n",
    "        \"planning_poker\": \"Planning Poker Project\",\n",
    "        \"recycling\": \"Recycling Project\",\n",
    "        \"color_ide\": \"ColorIDE Project\"\n",
    "    }\n",
    "projects = [\"archives_space\", \"neurohub\", \"open_spending\", \"planning_poker\", \"recycling\", \"color_ide\"]\n",
    "\n",
    "selected_project = os.environ.get(\"project\")\n",
    "if selected_project is None:\n",
    "    selected_project = projects[0]\n",
    "file_name = \"user_stories_{}.json\".format(selected_project)\n",
    "project_path = \"./input_files/{}\".format(file_name)\n",
    "with open(project_path, 'r') as file:\n",
    "        project_content = file.read()\n",
    "        project_title = project_title_map[selected_project]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:40:43.978726Z",
     "iopub.status.busy": "2025-02-07T12:40:43.978554Z",
     "iopub.status.idle": "2025-02-07T12:40:44.172337Z",
     "shell.execute_reply": "2025-02-07T12:40:44.171964Z"
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "\n",
    "#model_version = \"llama3.1:8b-instruct-fp16\"\n",
    "#model_version = \"deepseek-r1:70b\"\n",
    "model_version = \"llama3.1:70b\"\n",
    "num_ctx = 20480 # context length is higher because of the refinement process\n",
    "temperature = 0 # should be kept 0 for deterministic results, default value 0.8\n",
    "top_k = 0\n",
    "\n",
    "options = {\"num_ctx\": num_ctx, \"temperature\": temperature}\n",
    "model_name = model_version\n",
    "\n",
    "one_shot = False\n",
    "\n",
    "add_pattern_descriptions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load one-shot example if set True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:40:44.174522Z",
     "iopub.status.busy": "2025-02-07T12:40:44.174374Z",
     "iopub.status.idle": "2025-02-07T12:40:44.179212Z",
     "shell.execute_reply": "2025-02-07T12:40:44.178953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecture Pattern Descriptions:\\n\\nLayered Architecture: \\nLayered Architecture organizes the system into a set of layers, where each layer has a distinct responsibility and communicates only with its adjacent layers. This separation of concerns simplifies maintenance and testing.\\nEvent-Driven Architecture: \\nEvent-Driven Architecture centers on the production, detection, and consumption of events, enabling asynchronous communication among decoupled components.\\nMicrokernel Architecture: \\nMicrokernel Architecture features a minimal core system that handles essential services, while additional functionalities are provided through plug-in modules.\\nMicroservices Architecture: \\nMicroservices Architecture decomposes an application into a suite of small, independently deployable services, each responsible for a specific business function.\\nSpace-Based Architecture: \\nThe Space-Based Architecture pattern (also known as Cloud Architecture pattern) tackles scalability challenges by distributing application data and processing across multiple independent \"spaces.\" Each space contains a portion of the data and the logic to process it, minimizing bottlenecks and enabling horizontal scaling. Data is often replicated across spaces for fault tolerance and performance. A central coordinating mechanism manages these spaces, allowing them to dynamically scale up or down based on demand. This approach, commonly used in cloud environments, reduces the reliance on a central database constraint, enabling high scalability. This pattern is particularly effective for applications with variable and unpredictable user volumes, as it can dynamically adjust resources to meet demand, minimizing factors that typically limit scaling.\\nPipeline Architecture: \\nPipeline Architecture organizes the system into a series of processing stages (filters) connected by channels (pipes). Data flows through the pipeline, being transformed at each stage. It simplifies complex processing tasks by breaking them into smaller, independent steps.\\nClient-Server Architecture: \\nClient-Server Architecture separates the application into client components that request services and server components that provide services. This pattern is common in web applications, where the browser acts as the client and a web server acts as the server.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "if one_shot:\n",
    "    with open('example_reasoning_1.txt', 'r') as file:\n",
    "        example_run_text = file.read()\n",
    "        example_run_prompt = f\"\"\"\n",
    "        I will give you an example run for another software project just to show you the reasoning process and the output format. \n",
    "        VERY IMPORTANT NOTE: \"NEVER COPY THE REASONING GIVEN IN THE EXAMPLE RUN! This Example is for Reference Only, Come Up With Your Own Reasoning for The User Input!\"\n",
    "        - EXAMPLE RUN START - \n",
    "\n",
    "        {example_run_text}\n",
    "        \n",
    "        - EXAMPLE RUN END -\n",
    "\n",
    "        \"\"\"\n",
    "else:\n",
    "    example_run_prompt = \"\"\n",
    "\n",
    "if add_pattern_descriptions:\n",
    "    with open('pattern_descriptions.txt', 'r') as file:\n",
    "        pattern_descriptions_text = file.read()\n",
    "else:\n",
    "    pattern_descriptions_text = \"\"\n",
    "pattern_descriptions_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get first assessment from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:40:44.181240Z",
     "iopub.status.busy": "2025-02-07T12:40:44.181010Z",
     "iopub.status.idle": "2025-02-07T12:42:12.003514Z",
     "shell.execute_reply": "2025-02-07T12:42:12.001973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After analyzing the user stories for the ColorIDE Project, here are my detailed reasoning and scoring for each architecture pattern:\n",
      "\n",
      "**Layered Architecture**: This pattern is well-suited for the ColorIDE Project as it requires a clear separation of concerns between different components such as the editor, file explorer, terminal, and project loader. The layered architecture can help organize these components into distinct layers, making it easier to maintain and test the system.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want a simple and clean editor...\", \"As a developer, I want a file explorer...\", \"As a developer, I want a built-in terminal...\"\n",
      "\n",
      "Score: **Well suited**\n",
      "\n",
      "**Event-Driven Architecture**: While event-driven architecture can be useful for handling asynchronous events such as auto-completion and error highlighting, it may not be the best fit for the ColorIDE Project. The project's requirements do not seem to involve complex event handling or real-time processing.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want auto-completion and error highlighting...\"\n",
      "\n",
      "Score: **Partially suitable**\n",
      "\n",
      "**Microkernel Architecture**: This pattern is moderately applicable to the ColorIDE Project as it requires a minimal core system that provides essential editing and debugging capabilities. The microkernel architecture can help keep the core system small and efficient while allowing for additional functionalities to be added through plug-in modules.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want a simple plugin system...\", \"As a developer, I want the core to be modular...\"\n",
      "\n",
      "Score: **Moderately applicable**\n",
      "\n",
      "**Microservices Architecture**: This pattern is not well-suited for the ColorIDE Project as it requires a suite of small, independently deployable services. The project's requirements do not seem to involve multiple services that need to communicate with each other.\n",
      "\n",
      "Relevant user stories: None\n",
      "\n",
      "Score: **Completely unsuitable**\n",
      "\n",
      "**Space-Based Architecture**: This pattern is not applicable to the ColorIDE Project as it requires distributing application data and processing across multiple independent \"spaces\". The project's requirements do not seem to involve scalability challenges or variable user volumes.\n",
      "\n",
      "Relevant user stories: None\n",
      "\n",
      "Score: **Completely unsuitable**\n",
      "\n",
      "**Pipeline Architecture**: This pattern is partially suitable for the ColorIDE Project as it can help organize complex processing tasks such as auto-completion and error highlighting. However, the project's requirements do not seem to involve multiple stages of processing that need to be connected by channels.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want auto-completion and error highlighting...\"\n",
      "\n",
      "Score: **Partially suitable**\n",
      "\n",
      "**Client-Server Architecture**: This pattern is well-suited for the ColorIDE Project as it requires separating the application into client components that request services and server components that provide services. The project's requirements involve features such as Git integration and automatic updates, which can be implemented using a client-server architecture.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want easy Git integration...\", \"As a developer, I want the IDE to update automatically...\"\n",
      "\n",
      "Score: **Well suited**\n",
      "\n",
      "Here are the final scores in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"Layered Architecture\": \"Well suited\",\n",
      "  \"Event-Driven Architecture\": \"Partially suitable\",\n",
      "  \"Microkernel Architecture\": \"Moderately applicable\",\n",
      "  \"Microservices Architecture\": \"Completely unsuitable\",\n",
      "  \"Space-Based Architecture\": \"Completely unsuitable\",\n",
      "  \"Pipeline Architecture\": \"Partially suitable\",\n",
      "  \"Client-Server Architecture\": \"Well suited\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "client = Client(\n",
    "  headers={}\n",
    ")\n",
    "messages = []\n",
    "import time\n",
    "\n",
    "\n",
    "generator_system_message = {'role': 'system', 'content': f\"\"\"\n",
    "You are a software architect. Your task is to get a list of categorized user stories with a description, analyze them in detail and\n",
    "assign a score for each architecture pattern depending on their relevance to the project and \n",
    "if it would prove useful in the implementation of the described project.\n",
    "- Go over all of the user stories thoroughly, think step by step and explain your though process clearly. \n",
    "- Mention all specific user stories that helped you to make a decision.\n",
    "- Be as objective as possible during your scoring. The decisions need to be deterministic and reproducible.\n",
    "\n",
    "Here are the architecture patterns you will score:\n",
    "*Layered Architecture \n",
    "*Event-Driven Architecture\n",
    "*Microkernel Architecture \n",
    "*Microservices Architecture \n",
    "*Space-Based Architecture\n",
    "*Pipeline Architecture\n",
    "*Client-Server Architecture\n",
    "\n",
    "{pattern_descriptions_text}\n",
    "\n",
    "Here are the score options for the applicability of a pattern, ordered from lowest to highest, you must choose one of them for each pattern:\n",
    "- \"Completely unsuitable\"\n",
    "- \"Partially suitable\"\n",
    "- \"Moderately applicable\"\n",
    "- \"Well suited\"\n",
    "- \"Perfectly aligned\"\n",
    "\n",
    "IMPORTANT: First explain your reasoning for each pattern, mention the relevant user stories and then print the final scores in this json format:\n",
    "\n",
    "{{\n",
    "  \"Layered Architecture\": \"score option\",\n",
    "  \"Event-Driven Architecture\": \"score option\",\n",
    "  \"Microkernel Architecture\": \"score option\",\n",
    "  \"Microservices Architecture\": \"score option\",\n",
    "  \"Space-Based Architecture\": \"score option\",\n",
    "  \"Pipeline Architecture\": \"score option\",\n",
    "  \"Client-Server Architecture\": \"score option\"\n",
    "}}\n",
    "\n",
    "{example_run_prompt}\n",
    "\n",
    "\"\"\"}\n",
    "messages.append(generator_system_message)\n",
    "\n",
    "\n",
    "messages.append({'role': 'user', 'content': f\"\"\"\n",
    "I will give you a list of categorized user stories and a description created for a software project titled {project_title}. Please analyze them in detail and give me the scoring for each architecture pattern.\n",
    "The final scores must be given in json format after the detailed reasoning for each architecture pattern:\n",
    "\n",
    "{{\n",
    "  \"Layered Architecture\": \"score option\",\n",
    "  \"Event-Driven Architecture\": \"score option\",\n",
    "  \"Microkernel Architecture\": \"score option\",\n",
    "  \"Microservices Architecture\": \"score option\",\n",
    "  \"Space-Based Architecture\": \"score option\",\n",
    "  \"Pipeline Architecture\": \"score option\",\n",
    "  \"Client-Server Architecture\": \"score option\"\n",
    "}}\n",
    "\n",
    "Project Title: {project_title}\n",
    "\n",
    "Categorized User Stories:\n",
    "\n",
    "{project_content}\n",
    "\n",
    "\"\"\"})\n",
    "start_time = time.time()\n",
    "response = client.chat(model=model_name, messages=messages, options=options)\n",
    "end_time = time.time()\n",
    "score_generation_duration = end_time - start_time\n",
    "\n",
    "message = response['message']\n",
    "print(message['content'])\n",
    "messages.append(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-refinement Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:42:12.013293Z",
     "iopub.status.busy": "2025-02-07T12:42:12.012637Z",
     "iopub.status.idle": "2025-02-07T12:45:08.528810Z",
     "shell.execute_reply": "2025-02-07T12:45:08.527309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluator Feedback (Iteration 1) ===\n",
      "After re-evaluating the current reasoning and scores, I suggest the following refinements:\n",
      "\n",
      "**Event-Driven Architecture**: The score for Event-Driven Architecture should be raised to **Moderately applicable**. While the project's requirements do not seem to involve complex event handling or real-time processing, features like auto-completion and error highlighting can still benefit from an event-driven approach.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want auto-completion and error highlighting...\"\n",
      "\n",
      "Refined Score: **Moderately applicable**\n",
      "\n",
      "**Microkernel Architecture**: The score for Microkernel Architecture should be raised to **Well suited**. The project's requirements involve a minimal core system that provides essential editing and debugging capabilities, which aligns well with the microkernel architecture.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want a simple plugin system...\", \"As a developer, I want the core to be modular...\"\n",
      "\n",
      "Refined Score: **Well suited**\n",
      "\n",
      "**Pipeline Architecture**: The score for Pipeline Architecture should be lowered to **Completely unsuitable**. Upon re-evaluation, it appears that the project's requirements do not involve complex processing tasks that need to be organized into multiple stages.\n",
      "\n",
      "Relevant user stories: None\n",
      "\n",
      "Refined Score: **Completely unsuitable**\n",
      "\n",
      "Here is the refined JSON output:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"Layered Architecture\": \"Well suited\",\n",
      "  \"Event-Driven Architecture\": \"Moderately applicable\",\n",
      "  \"Microkernel Architecture\": \"Well suited\",\n",
      "  \"Microservices Architecture\": \"Completely unsuitable\",\n",
      "  \"Space-Based Architecture\": \"Completely unsuitable\",\n",
      "  \"Pipeline Architecture\": \"Completely unsuitable\",\n",
      "  \"Client-Server Architecture\": \"Well suited\"\n",
      "}\n",
      "```\n",
      "\n",
      "REFINE\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Refined Answer (Iteration 1) ===\n",
      "After re-evaluating the user stories for the ColorIDE Project and taking into account the evaluator's feedback, here are my refined reasoning and scoring for each architecture pattern:\n",
      "\n",
      "**Layered Architecture**: This pattern is well-suited for the ColorIDE Project as it requires a clear separation of concerns between different components such as the editor, file explorer, terminal, and project loader. The layered architecture can help organize these components into distinct layers, making it easier to maintain and test the system.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want a simple and clean editor...\", \"As a developer, I want a file explorer...\", \"As a developer, I want a built-in terminal...\"\n",
      "\n",
      "Score: **Well suited**\n",
      "\n",
      "**Event-Driven Architecture**: This pattern is moderately applicable to the ColorIDE Project as it can help handle asynchronous events such as auto-completion and error highlighting. While the project's requirements do not seem to involve complex event handling or real-time processing, features like auto-completion and error highlighting can still benefit from an event-driven approach.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want auto-completion and error highlighting...\"\n",
      "\n",
      "Score: **Moderately applicable**\n",
      "\n",
      "**Microkernel Architecture**: This pattern is well-suited for the ColorIDE Project as it requires a minimal core system that provides essential editing and debugging capabilities. The microkernel architecture can help keep the core system small and efficient while allowing for additional functionalities to be added through plug-in modules.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want a simple plugin system...\", \"As a developer, I want the core to be modular...\"\n",
      "\n",
      "Score: **Well suited**\n",
      "\n",
      "**Microservices Architecture**: This pattern is not well-suited for the ColorIDE Project as it requires a suite of small, independently deployable services. The project's requirements do not seem to involve multiple services that need to communicate with each other.\n",
      "\n",
      "Relevant user stories: None\n",
      "\n",
      "Score: **Completely unsuitable**\n",
      "\n",
      "**Space-Based Architecture**: This pattern is not applicable to the ColorIDE Project as it requires distributing application data and processing across multiple independent \"spaces\". The project's requirements do not seem to involve scalability challenges or variable user volumes.\n",
      "\n",
      "Relevant user stories: None\n",
      "\n",
      "Score: **Completely unsuitable**\n",
      "\n",
      "**Pipeline Architecture**: This pattern is not suitable for the ColorIDE Project as it does not require complex processing tasks that need to be organized into multiple stages.\n",
      "\n",
      "Relevant user stories: None\n",
      "\n",
      "Score: **Completely unsuitable**\n",
      "\n",
      "**Client-Server Architecture**: This pattern is well-suited for the ColorIDE Project as it requires separating the application into client components that request services and server components that provide services. The project's requirements involve features such as Git integration and automatic updates, which can be implemented using a client-server architecture.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want easy Git integration...\", \"As a developer, I want the IDE to update automatically...\"\n",
      "\n",
      "Score: **Well suited**\n",
      "\n",
      "Here are the refined scores in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"Layered Architecture\": \"Well suited\",\n",
      "  \"Event-Driven Architecture\": \"Moderately applicable\",\n",
      "  \"Microkernel Architecture\": \"Well suited\",\n",
      "  \"Microservices Architecture\": \"Completely unsuitable\",\n",
      "  \"Space-Based Architecture\": \"Completely unsuitable\",\n",
      "  \"Pipeline Architecture\": \"Completely unsuitable\",\n",
      "  \"Client-Server Architecture\": \"Well suited\"\n",
      "}\n",
      "```\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluator Feedback (Iteration 2) ===\n",
      "After re-evaluating the current reasoning and scores, I suggest no refinements. The current scores accurately reflect the suitability of each architecture pattern for the ColorIDE Project.\n",
      "\n",
      "The original categorized user stories were thoroughly analyzed, and the evaluator's feedback was taken into account to refine the scores. The resulting scores provide a clear indication of which architecture patterns are well-suited, moderately applicable, or completely unsuitable for the project.\n",
      "\n",
      "Therefore, I suggest no changes to the current scores.\n",
      "\n",
      "NO_REFINEMENT\n",
      "\n",
      "Evaluator says no changes are needed. Stopping refinement.\n",
      "=== Final Refined Scores & Reasoning ===\n",
      " After re-evaluating the user stories for the ColorIDE Project and taking into account the evaluator's feedback, here are my refined reasoning and scoring for each architecture pattern:\n",
      "\n",
      "**Layered Architecture**: This pattern is well-suited for the ColorIDE Project as it requires a clear separation of concerns between different components such as the editor, file explorer, terminal, and project loader. The layered architecture can help organize these components into distinct layers, making it easier to maintain and test the system.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want a simple and clean editor...\", \"As a developer, I want a file explorer...\", \"As a developer, I want a built-in terminal...\"\n",
      "\n",
      "Score: **Well suited**\n",
      "\n",
      "**Event-Driven Architecture**: This pattern is moderately applicable to the ColorIDE Project as it can help handle asynchronous events such as auto-completion and error highlighting. While the project's requirements do not seem to involve complex event handling or real-time processing, features like auto-completion and error highlighting can still benefit from an event-driven approach.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want auto-completion and error highlighting...\"\n",
      "\n",
      "Score: **Moderately applicable**\n",
      "\n",
      "**Microkernel Architecture**: This pattern is well-suited for the ColorIDE Project as it requires a minimal core system that provides essential editing and debugging capabilities. The microkernel architecture can help keep the core system small and efficient while allowing for additional functionalities to be added through plug-in modules.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want a simple plugin system...\", \"As a developer, I want the core to be modular...\"\n",
      "\n",
      "Score: **Well suited**\n",
      "\n",
      "**Microservices Architecture**: This pattern is not well-suited for the ColorIDE Project as it requires a suite of small, independently deployable services. The project's requirements do not seem to involve multiple services that need to communicate with each other.\n",
      "\n",
      "Relevant user stories: None\n",
      "\n",
      "Score: **Completely unsuitable**\n",
      "\n",
      "**Space-Based Architecture**: This pattern is not applicable to the ColorIDE Project as it requires distributing application data and processing across multiple independent \"spaces\". The project's requirements do not seem to involve scalability challenges or variable user volumes.\n",
      "\n",
      "Relevant user stories: None\n",
      "\n",
      "Score: **Completely unsuitable**\n",
      "\n",
      "**Pipeline Architecture**: This pattern is not suitable for the ColorIDE Project as it does not require complex processing tasks that need to be organized into multiple stages.\n",
      "\n",
      "Relevant user stories: None\n",
      "\n",
      "Score: **Completely unsuitable**\n",
      "\n",
      "**Client-Server Architecture**: This pattern is well-suited for the ColorIDE Project as it requires separating the application into client components that request services and server components that provide services. The project's requirements involve features such as Git integration and automatic updates, which can be implemented using a client-server architecture.\n",
      "\n",
      "Relevant user stories: \"As a developer, I want easy Git integration...\", \"As a developer, I want the IDE to update automatically...\"\n",
      "\n",
      "Score: **Well suited**\n",
      "\n",
      "Here are the refined scores in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"Layered Architecture\": \"Well suited\",\n",
      "  \"Event-Driven Architecture\": \"Moderately applicable\",\n",
      "  \"Microkernel Architecture\": \"Well suited\",\n",
      "  \"Microservices Architecture\": \"Completely unsuitable\",\n",
      "  \"Space-Based Architecture\": \"Completely unsuitable\",\n",
      "  \"Pipeline Architecture\": \"Completely unsuitable\",\n",
      "  \"Client-Server Architecture\": \"Well suited\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's capture the model's initial answer in a variable:\n",
    "current_answer = message['content']  # e.g. the text with reasoning + final scores\n",
    "evaluator_context = messages.copy() # this context will be used in evaluator messages\n",
    "eval_system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "Your task has changed. You are now the Evaluator.\n",
    "Your job is to thoroughly review the user stories, evaluate the provided reasoning and scores for each architectural pattern, and clearly recommend any necessary score adjustments—explicitly indicating whether they should be raised or lowered, as this distinction is critical. \n",
    "- Mention all specific user stories that are relevant to your refinement suggestions.\n",
    "\n",
    "Here are the score options for the applicabilitylity of a pattern, ordered from lowest to highest:\n",
    "- \"Completely unsuitable\"\n",
    "- \"Partially suitable\"\n",
    "- \"Moderately applicable\"\n",
    "- \"Well suited\"\n",
    "- \"Perfectly aligned\"\n",
    "\n",
    "- Do not assume any new information about the project. The description and the user stories for the project remain the same. Do not suggest refinements for possible future changes.\n",
    "- Only suggest a refinement when you are certain that the assigned score is incorrect and needs adjustment.\n",
    "- Also, review your previous evaluations to ensure you don’t repeat the same refinement suggestion for an architecture pattern for the same reason.\n",
    "\n",
    "After your refinement suggestions, on a NEW line, end your response with exactly one of the two markers:\n",
    "- REFINE (if refinements are needed)\n",
    "- NO_REFINEMENT (if no refinements are needed)\n",
    "\n",
    "Do not include any additional text after that marker.\n",
    "Do not wrap it in quotes.\n",
    "\n",
    "Important:\n",
    "- Score can only be assigned one of the integer values that are given as the score options, no float values.\n",
    "- If you provide refinement for any of the pattern scores, do not use NO_REFINEMENT.\n",
    "Because this will stop the whole process and the current scores will be left unrefined.\n",
    "- Use NO_REFINEMENT only if you have zero refinements to suggest.\n",
    "\"\"\"\n",
    "}\n",
    "evaluator_context.append(eval_system_message)\n",
    "\n",
    "refiner_context = messages.copy() # this context will be used in refiner messages\n",
    "\n",
    "refine_system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "Your task has changed. You are now the Refiner. \n",
    "You will be given the latest reasoning/scores for the project and the evaluator's feedback for the latest reasoning/scores.\n",
    "Make changes to the current scores according to the provided refinement suggestions\n",
    "- Do not assume any new information about the project. The description and the user stories for the project remain the same.\n",
    "- IMPORTANT:  ONLY make a change for a score when the refinement suggestion for that score is reasonable and the assigned score must change. Otherwise keep it unchanged.\n",
    "\n",
    "When returning the refined scores, keep the same format in the updated response (reasoning and then the updated scores in json format).\n",
    "\n",
    "Here are the score options for the applicability of a pattern, ordered from lowest to highest, you must choose one of them for each pattern:\n",
    "- \"Completely unsuitable\"\n",
    "- \"Partially suitable\"\n",
    "- \"Moderately applicable\"\n",
    "- \"Well suited\"\n",
    "- \"Perfectly aligned\"\n",
    "\n",
    "\"\"\"\n",
    "    }\n",
    "refiner_context.append(refine_system_message)\n",
    "# We'll define how many refinement loops to allow:\n",
    "MAX_REFINEMENT_ITERATIONS = 2\n",
    "\n",
    "start_time = time.time()\n",
    "refinement_iterations = MAX_REFINEMENT_ITERATIONS # if not set again in the loop, it means the model went through max iterations\n",
    "for i in range(MAX_REFINEMENT_ITERATIONS):\n",
    "    # 1) Evaluate the current answer\n",
    "    \n",
    "    evaluate_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "            Evaluate the current reasoning and scores by taking the original categorized user stories into account and make refinement suggestions for the current answer:\n",
    "\n",
    "            Current Answer:\n",
    "            {current_answer}\n",
    "\n",
    "            Refinement Suggestions:\n",
    "            \"\"\"\n",
    "    }\n",
    "    evaluator_context.append(evaluate_prompt)\n",
    "    eval_response = client.chat(model=model_name, messages=evaluator_context, options=options)\n",
    "    eval_message = eval_response['message']\n",
    "    eval_feedback = eval_message['content'].strip()\n",
    "    evaluator_context.append(eval_message)\n",
    "    \n",
    "    print(f\"\\n=== Evaluator Feedback (Iteration {i+1}) ===\\n{eval_feedback}\\n\")\n",
    "    \n",
    "    # 2) If the evaluator indicates no changes are needed, break out\n",
    "    if \"NO_REFINEMENT\" in eval_feedback:\n",
    "        print(\"Evaluator says no changes are needed. Stopping refinement.\")\n",
    "        refinement_iterations = i\n",
    "        break\n",
    "    \n",
    "    # 3) Otherwise, refine\n",
    "    refine_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "            Analyze the previous answer and the feedback of the evaluator, and then refine your previous answer by taking the feedback of the evaluator into account. \n",
    "            Keep the same format (reasoning and then the final scores in json format).\n",
    "\n",
    "            Previous Answer:\n",
    "            {current_answer}\n",
    "\n",
    "            Evaluator Feedback:\n",
    "            {eval_feedback}\n",
    "\n",
    "            Revised Answer:\n",
    "            \"\"\"\n",
    "    }\n",
    "    refiner_context.append(refine_prompt)\n",
    "    \n",
    "    refine_response = client.chat(model=model_name, messages=refiner_context, options=options)\n",
    "    refine_message = refine_response['message']\n",
    "    revised_answer = refine_message['content'].strip()\n",
    "    refiner_context.append(refine_message)\n",
    "    \n",
    "    print(f\"=== Refined Answer (Iteration {i+1}) ===\\n{revised_answer}\\n\")\n",
    "    \n",
    "    # Update current_answer for potential next iteration\n",
    "    current_answer = revised_answer\n",
    "\n",
    "end_time = time.time()\n",
    "refinement_duration = end_time - start_time\n",
    "# After the loop, current_answer holds the final refined output:\n",
    "print(\"=== Final Refined Scores & Reasoning ===\\n\", current_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:45:08.537599Z",
     "iopub.status.busy": "2025-02-07T12:45:08.537202Z",
     "iopub.status.idle": "2025-02-07T12:45:46.513375Z",
     "shell.execute_reply": "2025-02-07T12:45:46.512464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the final scores before and after the evaluation-refinement process in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"Layered Architecture\": {\"before\": \"Well suited\", \"after\": \"Well suited\"},\n",
      "  \"Event-Driven Architecture\": {\"before\": \"Partially suitable\", \"after\": \"Moderately applicable\"},\n",
      "  \"Microkernel Architecture\": {\"before\": \"Moderately applicable\", \"after\": \"Well suited\"},\n",
      "  \"Microservices Architecture\": {\"before\": \"Completely unsuitable\", \"after\": \"Completely unsuitable\"},\n",
      "  \"Space-Based Architecture\": {\"before\": \"Completely unsuitable\", \"after\": \"Completely unsuitable\"},\n",
      "  \"Pipeline Architecture\": {\"before\": \"Partially suitable\", \"after\": \"Completely unsuitable\"},\n",
      "  \"Client-Server Architecture\": {\"before\": \"Well suited\", \"after\": \"Well suited\"}\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "refiner_context.append({'role': 'system', 'content': \"\"\"\n",
    "Ok now the evaluation process is finished. take the first assessment and the last assessment from the user. \n",
    "And just return the final scores before and after the evaluation-refinement process\n",
    "following this json format below:\n",
    "\n",
    "{\n",
    "  \"Layered Architecture\": {\"before\": \"score option\", \"after\": \"score option\"},\n",
    "  \"Event-Driven Architecture\": {\"before\": \"score option\", \"after\": \"score option\"},\n",
    "  \"Microkernel Architecture\": {\"before\": \"score option\", \"after\": \"score option\"},\n",
    "  \"Microservices Architecture\": {\"before\": \"score option\", \"after\": \"score option\"},\n",
    "  \"Space-Based Architecture\": {\"before\": \"score option\", \"after\": \"score option\"},\n",
    "  \"Pipeline Architecture\": {\"before\": \"score option\", \"after\": \"score option\"},\n",
    "  \"Client-Server Architecture\": {\"before\": \"score option\", \"after\": \"score option\"}\n",
    "}\n",
    "\"\"\"})\n",
    "\n",
    "refiner_context.append({'role': 'user', 'content': f\"\"\"\n",
    "read the first assessment and the last assessment, and return the final scores before and after the evaluation-refinement process\n",
    "following this json format below:\n",
    "\n",
    "{{\n",
    "  \"Layered Architecture\": {{\"before\": \"score option\", \"after\": \"score option\"}},\n",
    "  \"Event-Driven Architecture\": {{\"before\": \"score option\", \"after\": \"score option\"}},\n",
    "  \"Microkernel Architecture\": {{\"before\": \"score option\", \"after\": \"score option\"}},\n",
    "  \"Microservices Architecture\": {{\"before\": \"score option\", \"after\": \"score option\"}},\n",
    "  \"Space-Based Architecture\": {{\"before\": \"score option\", \"after\": \"score option\"}},\n",
    "  \"Pipeline Architecture\": {{\"before\": \"score option\", \"after\": \"score option\"}},\n",
    "  \"Client-Server Architecture\": {{\"before\": \"score option\", \"after\": \"score option\"}}\n",
    "}}\n",
    "\n",
    "\n",
    "first assessment:\n",
    "{refiner_context[2][\"content\"].strip()}\n",
    "\n",
    "last assessment:\n",
    "{current_answer.strip()}\n",
    "\"\"\"})\n",
    "response = client.chat(model=model_name, messages=refiner_context, options={\"num_ctx\": num_ctx, \"temperature\": 0}) # need deterministic answer\n",
    "message = response['message']\n",
    "refiner_context.append(message)\n",
    "print(message[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:45:46.519596Z",
     "iopub.status.busy": "2025-02-07T12:45:46.519302Z",
     "iopub.status.idle": "2025-02-07T12:45:46.525144Z",
     "shell.execute_reply": "2025-02-07T12:45:46.524567Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json_in_string(s):\n",
    "    \"\"\"\n",
    "    Parses and returns the first JSON object found in the input string.\n",
    "\n",
    "    Args:\n",
    "        s (str): The input string that contains at least one JSON object.\n",
    "\n",
    "    Returns:\n",
    "        object: The Python representation of the parsed JSON object.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no JSON object is found or if decoding fails.\n",
    "    \"\"\"\n",
    "    # Find the first occurrence of '{'\n",
    "    start = s.find('{')\n",
    "    if start == -1:\n",
    "         return None\n",
    "\n",
    "    decoder = json.JSONDecoder()\n",
    "    try:\n",
    "        obj, _ = decoder.raw_decode(s, idx=start)\n",
    "        return obj\n",
    "    except json.JSONDecodeError as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate kappa score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:45:46.528899Z",
     "iopub.status.busy": "2025-02-07T12:45:46.528641Z",
     "iopub.status.idle": "2025-02-07T12:45:47.202375Z",
     "shell.execute_reply": "2025-02-07T12:45:47.201687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 0.3950617283950617, After: 0.5333333333333332\n",
      "Before Scores: [4, 2, 3, 1, 1, 2, 4], After Scores: [4, 3, 4, 1, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/r79c48353r5cvd6d3tz920_h0000gn/T/ipykernel_23787/3923727384.py:5: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  refiner_context = [message if isinstance(message, dict) else message.dict() for message in refiner_context]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "architecture_patterns = [\"Layered Architecture\", \"Event-Driven Architecture\",\n",
    " \"Microkernel Architecture\", \"Microservices Architecture\", \"Space-Based Architecture\", \"Pipeline Architecture\", \"Client-Server Architecture\"]\n",
    "\n",
    "refiner_context = [message if isinstance(message, dict) else message.dict() for message in refiner_context]\n",
    "\n",
    "scores = {\"Completely unsuitable\": 1, \"Partially suitable\": 2, \"Moderately applicable\": 3, \"Well suited\": 4, \"Well-suited\":4, \"Perfectly aligned\": 5}\n",
    "with open('expert_answers.json') as f:\n",
    "    expert_answers = json.load(f)\n",
    "llm_answers = parse_json_in_string(refiner_context[-1][\"content\"])\n",
    "answers_before = [scores[llm_answers[pattern][\"before\"]] for pattern in architecture_patterns]\n",
    "answers_after = [scores[llm_answers[pattern][\"after\"]] for pattern in architecture_patterns]\n",
    "score_before_refinement = cohen_kappa_score(expert_answers[selected_project], answers_before, labels=[1, 2, 3, 4, 5], weights='quadratic')\n",
    "score_after_refinement = cohen_kappa_score(expert_answers[selected_project], answers_after, labels=[1, 2, 3, 4, 5], weights='quadratic')\n",
    "\n",
    "print(f\"Before: {score_before_refinement}, After: {score_after_refinement}\")\n",
    "print(f\"Before Scores: {answers_before}, After Scores: {answers_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print log to output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T12:45:47.205101Z",
     "iopub.status.busy": "2025-02-07T12:45:47.204882Z",
     "iopub.status.idle": "2025-02-07T12:45:47.209949Z",
     "shell.execute_reply": "2025-02-07T12:45:47.209676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assesment complete. The whole conversation is saved to ./logs/self-refinement-zero-shot/log_llama3.1:70b_20250207_134547.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "Path(\"./logs/self-refinement-one-shot\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"./logs/self-refinement-zero-shot\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "final_data = {\n",
    "        \"modelName\": model_name,\n",
    "        \"temperature\": temperature,\n",
    "        \"context_limit\": num_ctx,\n",
    "        \"options\": options,\n",
    "        \"projectTitle\": project_title,\n",
    "        \"file_name\": file_name,\n",
    "        \"selfRefinement\": True,\n",
    "        \"oneShot\": one_shot,\n",
    "        \"wckScoreBeforeRefinement\": score_before_refinement,\n",
    "        \"wckScoreAfterRefinement\": score_after_refinement,\n",
    "        \"patternDescriptionsAdded\": add_pattern_descriptions,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        \"json_output_parsed\": parse_json_in_string(refiner_context[-1][\"content\"]),\n",
    "        \"numberOfIterations\": refinement_iterations,\n",
    "        \"maxIterationsAllowed\": MAX_REFINEMENT_ITERATIONS,\n",
    "        \"messages\": [message[\"content\"] for message in refiner_context],\n",
    "        \"scoreGenerationDuration\": score_generation_duration,\n",
    "        \"refinementDuration\": refinement_duration\n",
    "    }\n",
    "    \n",
    "# 3) Generate a filename based on model name and current timestamp\n",
    "if one_shot:\n",
    "    filename = f\"./logs/self-refinement-one-shot/log_{model_version}_{final_data['timestamp']}.json\"\n",
    "else:\n",
    "    filename = f\"./logs/self-refinement-zero-shot/log_{model_version}_{final_data['timestamp']}.json\"\n",
    "# 4) Write the conversation to a JSON file\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Assesment complete. The whole conversation is saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95ec9ec1504d83f612128e0fb229072f90bbb4cb09d9d5d93b5dd26e0ca2cfd1"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "pip install ollama\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: ollama in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (0.4.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from ollama) (2.10.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.2.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2.10)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T15:02:44.149935Z",
     "iopub.status.busy": "2024-11-28T15:02:44.149036Z",
     "iopub.status.idle": "2024-11-28T15:02:46.988655Z",
     "shell.execute_reply": "2024-11-28T15:02:46.987904Z",
     "shell.execute_reply.started": "2024-11-28T15:02:44.149875Z"
    },
    "trusted": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load model and configure model parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "\n",
    "model_version = \"llama3.1:8b-instruct-fp16\"\n",
    "num_ctx = 16384 #context window - token allowed for each message, need to increase from default value of 2048 as our messages may overflow\n",
    "temperature = \"0\" # should be kept low for deterministic results, default value 1\n",
    "top_p = \"1\" \n",
    "#model_version = \"llama3.1:70b\"\n",
    "modelfile='''\n",
    "FROM {}\n",
    "PARAMETER num_ctx {}\n",
    "PARAMETER temperature {}\n",
    "\n",
    "'''.format(model_version, num_ctx, temperature)\n",
    "\n",
    "#model_name = \"emir_\" + model_version + \"_t_\" + \"{:.2f}\".format(temperature)\n",
    "model_name = \"emir_\" + model_version\n",
    "#model_name = model_version\n",
    "ollama.create(model=model_name, modelfile=modelfile)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ResponseError",
     "evalue": "registry.ollama.ai/library/llama3.3:latest: EOF",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memir_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_version\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#model_name = model_version\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ollama/_client.py:517\u001b[0m, in \u001b[0;36mClient.create\u001b[0;34m(self, model, path, modelfile, quantize, stream)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust provide either path or modelfile\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m  \u001b[49m\u001b[43mProgressResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/create\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ollama/_client.py:175\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    173\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/ollama/_client.py:120\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m   r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 120\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mResponseError\u001b[0m: registry.ollama.ai/library/llama3.3:latest: EOF"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get first assessment from model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "client = Client(\n",
    "  headers={}\n",
    ")\n",
    "messages = []\n",
    "\n",
    "generator_system_message = {'role': 'system', 'content': \"\"\"\n",
    "You are a software architect. Your job is to get a list of categorized user stories, analyze them in detail and\n",
    "assign a score for each architecture pattern depending on their relevance to the project and \n",
    "if it would prove useful in the implementation of the described project.\n",
    "\n",
    "When the user gives you a list of user stories, analyze the given user stories, give the reasoning for each architecture pattern, and then print out the assigned scores.\n",
    "\n",
    "Here are the architecture patterns you will score:\n",
    "*Layered Architecture \n",
    "*Event-Driven Architecture (Pub-Sub Architecture) \n",
    "*Microkernel Architecture \n",
    "*Microservices Architecture \n",
    "*Space-Based Architecture\n",
    "*Pipeline Architecture (Pipe-Filter Architecture) \n",
    "*Client-Server Architecture\n",
    "\n",
    "Here are the descriptions for each pattern and usage examples:\n",
    "\n",
    "*Layered Architecture\n",
    "Layered Architecture organizes software into horizontal layers, each with distinct responsibilities such as presentation, business logic, and data persistence. The core idea is that each layer only interacts with the layer directly beneath it, which makes the system more manageable and easier to maintain. Changes within a single layer can often be made without affecting other layers, enhancing modifiability. It also facilitates the separation of concerns, allowing teams to focus on specific layers without impacting the entire system. However, it can introduce performance overhead if there are many layers and each request must pass through them.\n",
    "Typical Usage Example:\n",
    "A common example is an enterprise web application with a front-end/UI layer, a service or business logic layer, and a database access layer. For instance, many Java EE or .NET applications follow a Layered Architecture to clearly separate presentation, business, and data access concerns.\n",
    "\n",
    "*Event-Driven Architecture (Pub-Sub Architecture)\n",
    "In an Event-Driven Architecture, components communicate primarily through the production and consumption of events. Publishers emit events without knowing which subscribers will be interested in them, and subscribers react when they receive relevant events. This decouples event producers from consumers, making the system more flexible and scalable. It also allows for asynchronous processing, where components can respond to events at different times. However, debugging can be more complex due to the non-linear flow of events and the indirect communication paths.\n",
    "Typical Usage Example:\n",
    "A common example is a messaging system with a message broker like Apache Kafka or RabbitMQ. For instance, e-commerce platforms use an event-driven approach to process inventory updates, orders, and notifications asynchronously.\n",
    "\n",
    "*Microkernel Architecture\n",
    "Microkernel Architecture (also known as Plugin Architecture) consists of a core system, or “kernel,” that provides the fundamental services, and additional features are implemented as plug-in modules around it. The core is kept minimal and stable, with most business logic or specialized features added through extensions or plugins. This allows for easy customization and extensibility, since new modules can be added without modifying the kernel. It also improves system resilience because a faulty plugin can be disabled or replaced without bringing down the entire system. However, designing a robust microkernel can be complex as it must accommodate a wide range of future extensions.\n",
    "Typical Usage Example:\n",
    "Examples include operating systems like the early versions of Mac OS X (with its Mach microkernel) and Eclipse IDE, where the core platform loads various plugin modules for functionality such as language support, testing tools, or version control integrations.\n",
    "\n",
    "*Microservices Architecture\n",
    "Microservices Architecture breaks down an application into smaller, independently deployable services, each responsible for a specific business capability. Each service can be built, tested, deployed, and scaled independently, which promotes agility and faster development cycles. Teams can choose different technologies or databases for each service if needed, providing flexibility. However, this approach introduces complexity in inter-service communication, monitoring, and data consistency. DevOps, CI/CD pipelines, and robust service discovery mechanisms are usually critical for successful microservices deployments.\n",
    "Typical Usage Example:\n",
    "Netflix is a well-known practitioner of microservices, splitting its platform into small, specialized services for managing user data, recommendation algorithms, and video streaming, among others. Likewise, many modern e-commerce companies adopt microservices to handle catalog services, shopping cart, and payment services separately.\n",
    "\n",
    "*Space-Based Architecture\n",
    "Space-Based Architecture (also called Cloud-Based or Tuple Space Architecture) uses the concept of a “data grid” or “processing grid,” where the application components share a common distributed memory or “space.” It is designed to handle high scalability and peak loads by distributing both the data and the processing across multiple nodes. Components can write data or tasks into the space, and other components pick up the tasks or data for processing. This approach reduces bottlenecks by avoiding central databases at high transaction volumes. However, it can be more complex to implement and manage due to the distributed nature of both data and processing.\n",
    "Typical Usage Example:\n",
    "Retail websites dealing with heavy seasonal traffic (like Black Friday sales) might use space-based architecture to handle massive spikes in transactions. GigaSpaces is a known platform that implements this pattern to allow for in-memory data sharing and fast scaling.\n",
    "\n",
    "*Pipeline Architecture (Pipe-Filter Architecture)\n",
    "Pipeline Architecture, also known as Pipe-Filter, organizes processing steps into a sequence of filters, where the output of one filter is the input to the next. Each filter performs a distinct operation, and data flows continuously through the pipeline. This makes the system modular, as filters can be swapped or reordered without changing the surrounding components. It is particularly suitable for data processing or transformation workflows. However, it might not be optimal for interactive applications needing bidirectional communication.\n",
    "Typical Usage Example:\n",
    "A classic example is a data processing workflow in ETL (Extract, Transform, Load) operations, where you have steps for extracting raw data, cleaning and transforming it, and finally loading it into a target system or database.\n",
    "\n",
    "*Client-Server Architecture\n",
    "Client-Server Architecture divides the system into two main parts: clients that request services or resources, and a server that processes these requests and returns a response. This structure simplifies the way users interact with shared data or centralized processes. The server can be scaled up independently, and security or permissions can be centrally managed. However, if the server fails or becomes overloaded, clients will be unable to access the service. It remains a fundamental design pattern for many networked applications.\n",
    "Typical Usage Example:\n",
    "Any typical web application employs a client-server setup: a web browser (client) connects to a remote web server to fetch and display web pages. Another example is email clients communicating with a mail server over protocols like IMAP/POP3 for receiving mail and SMTP for sending mail.\n",
    "\n",
    "\n",
    "Here are the score options and their corresponding meaning:\n",
    "1: \"Completely unsuitable\"\n",
    "2: \"Partially suitable\"\n",
    "3: \"Sufficient for requirements\"\n",
    "4: \"Well-suited\"\n",
    "5: \"Perfectly aligned\"\n",
    "\n",
    "The final scores must be given in this format after the detailed reasoning for each architecture pattern:\n",
    "\n",
    "**Layered Architecture**: 1\n",
    "**Event-Driven Architecture (Pub-Sub Architecture)**: 4\n",
    "**Microkernel Architecture**: 2\n",
    "**Microservices Architecture**: 3\n",
    "**Space-Based Architecture**: 1\n",
    "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
    "**Client-Server Architecture**: 3\n",
    "\n",
    "\"\"\"}\n",
    "messages.append(generator_system_message)\n",
    "\n",
    "\n",
    "messages.append({'role': 'user', 'content': \"\"\"\n",
    "I will give you a list of categorized user stories created for a software project. Please analyze them in detail and give me the scoring for each architecture pattern:\n",
    "\n",
    "User Stories:\n",
    "\n",
    "{\n",
    "    \"Usability & Accessibility\": [\n",
    "      \"As a moderator, I want to start a round by entering an item in a single multi-line text field, so that we can estimate it.\",\n",
    "      \"As a moderator, I want to see all items we try to estimate this session, so that I can answer questions about the current story such as \\\"does this include ___?\\\".\",\n",
    "      \"As a moderator, I want to add an item to the list of items to be estimated, so that so that we can be flexible and accommodate situations where we think of a new story while playing.\",\n",
    "      \"As a moderator, I want to edit an item in the list of items to be estimated, so that I can make it better reflect the team's understanding of the item.\",\n",
    "      \"As a moderator, I want to delete an item from the list of items to be estimated, so that we can remove it and not estimate it.\",\n",
    "      \"As a moderator, I want to show all estimates immediately, so that I can decide to show the estimates that have been given even though not all estimators have given their estimate.\",\n",
    "      \"As a moderator, I want to accept the average of all estimates, so that we can move on to the next item when we agree.\",\n",
    "      \"As a moderator, I want to have the \\\"estimate\\\" field filled in automatically if all estimators show the same card, so that I can accept it more quickly.\",\n",
    "      \"As a moderator, I want to enter the agreed-upon estimate, so that we can move on to the next item when we agree.\",\n",
    "      \"As a moderator, I want to estimate a story we estimated earlier in the session again, so that we can give a new estimate if we feel different about the story after estimating other related stories.\",\n",
    "      \"As a moderator, I want to copy/paste stories from a spreadsheet, so that I can get started more quickly.\",\n",
    "      \"As a moderator, I want to view a transcript of a game, so that I can see the stories and estimates.\",\n",
    "      \"As a moderator, I want to see dates and times in my local timezone, so that I don't have to do timezone conversion myself.\",\n",
    "      \"As an estimator, I want to see the item weíre estimating, so that I know what Iím giving an estimate for.\",\n",
    "      \"As an estimator, I want to see all items we will try to estimate this session, so that I have a feel for the sizes of the various items.\",\n",
    "      \"As a participant, I want to immediately see that an estimate has been given by a specific estimator, so that I know who has already given an estimate and who weíre still waiting for.\",\n",
    "      \"As a participant, I want to be able to change my estimate up until the last person selects a card and all are shown, so that I can change my mind based on information I hear.\",\n",
    "      \"As a participant, I want to be able to see each estimator's prior estimates for the story being estimated, so that I can see how his or her opinion has changed so I can ask questions.\",\n",
    "      \"As a participant, I want to see who gave what estimates during the current round, so that I know this when weíre discussing the estimates.\",\n",
    "      \"As a participant, I want to be able start a two-minute countdown timer that all participants can see, so that I can limit the time spent discussing the estimates when I think weíve talked long enough.\",\n",
    "      \"As a participant, I want to have the two-minute timer reset itself as soon as we all play an estimate, so that it's ready for use on the next round.\",\n",
    "      \"As a participant, I want to scroll back through the stories and estimates from prior rounds, so that I can use this information when I estimate the item of the current round.\",\n",
    "      \"As a participant, I want to always have the cards in the same order across multiple draws, so that it's easy to compare estimates.\",\n",
    "      \"As a participant, I want to change my estimate as long as the draw has not been completed, so that I can change my mind.\",\n",
    "      \"As a participant, I want to have a small thumbnail photo displayed near where my cards are played, so that the game is more personal because I see who I'm estimating with.\",\n",
    "      \"As a user, I want to have the application respond quickly to my actions, so that I don't get bored.\",\n",
    "      \"As a user, I want to be able to use Unicode, so that I can use any language I like.\",\n",
    "      \"As a user, I want to see sensible and predictable URLs, so that the application feels logical and transparent.\",\n",
    "      \"As a user, I want to have nice error pages when something goes wrong, so that I can trust the system and its developers.\"\n",
    "    ],\n",
    "    \"Integrability & Interoperability\": [\n",
    "      \"As a moderator, I want to import stories from a spreadsheet, so that I don't have to copy and paste each individual story.\",\n",
    "      \"As a moderator, I want to export a transcript of a game as a HTML file, so that I can save the stories and estimates locally.\",\n",
    "      \"As a moderator, I want to export a transcript of a game as a CSV file, so that I can further process the stories and estimates.\"\n",
    "    ],\n",
    "    \"Security & Confidentiality\": [\n",
    "      \"As a Researcher, I want results to be stored in a non-identifiable way, so that I can study the data to see things like whether estimates converged around the first opinion given by \\\"estimator A\\\" for example.\"\n",
    "    ],\n",
    "    \"Manageability & Maintainability\": [\n",
    "      \"As a moderator, I want to create a new game by entering a name and an optional description, so that I can start inviting estimators.\",\n",
    "      \"As a moderator, I want to select an item to be estimated or re-estimated, so that the team sees that item and can estimate it.\",\n",
    "      \"As a moderator, I want to browse through previous games, so that I can find the previous game Iím looking for.\",\n",
    "      \"As a moderator, I want to delete a game, so that stories and estimates for this game are no longer stored.\",\n",
    "      \"As a moderator, I want to create an account for the application by entering my name, email address, a password and a username, so that I can start using the application.\",\n",
    "      \"As a moderator, I want to change my account details, so that I can keep my account details up-to-date.\",\n",
    "      \"As a moderator, I want to delete my account, so that account information and games are no longer stored.\",\n",
    "      \"As a moderator, I want to get a password reminder by email, so that I can get back to using the application when I've forgotten my password.\",\n",
    "      \"As a moderator, I want to invite up to 15 estimators, so that we can play with large but not immense teams.\",\n",
    "      \"As a developer, I want to have a list of definitions for commonly used terms, so that everyone working on the project can understand each other more easily.\"\n",
    "    ],\n",
    "    \"Modularity & Extensibility\": [\n",
    "      \"As a moderator, I want to invite estimators by giving them a URL where they can access the game, so that we can start the game.\",\n",
    "      \"As a estimator, I want to join a game by entering my name on the page I received the URL for, so that I can participate.\",\n",
    "      \"As a participant, I want to be shown all estimates at the same time after all estimators have given their estimate, so that I can be sure estimates are independent and not influenced by other estimates given in the same draw.\"\n",
    "    ],\n",
    "    \"Performance Efficiency & Resource Utilization\": [\n",
    "      \"As a developer, I want to have created database indexes, so that the queries run as fast as possible.\"\n",
    "    ],\n",
    "    \"Variability & Flexibility\": [\n",
    "      \"As a moderator, I want to select whether to have the team estimate with {0, 1/2, 1, 2, 3, 5, 8, etc.} or {0, 1, 2, 4, 8, 16, 32, etc.}, so that the team can use either the modified Fibonacci sequence or powers of 2.\"\n",
    "    ],\n",
    "    \"Implementability & Ease of Development\": [\n",
    "      \"As a developer, I want to have written a site which is compliant with XHTML and CSS standards, so that as many people as possible can access the site and view it as intended.\",\n",
    "      \"As a developer, I want to have the application function correctly in Internet Explorer 6 and 7, Firefox 1.5 and 2, and Safari 2, so that as many people as possible can fully use the application.\",\n",
    "      \"As a developer, I want to have the site comply with the W3C accessibility guidelines where possible, so that people with accessibility issues can use the application.\"\n",
    "    ],\n",
    "    \"Exchangeability & Replaceability\": [],\n",
    "    \"Analyzability & Traceability\": [\n",
    "      \"As a developer, I want to be able to see some metrics on use of the game, so that I can see how much it is being used.\"\n",
    "    ]\n",
    "  }\n",
    "\n",
    "\"\"\"})\n",
    "response = client.chat(model=model_name, messages=messages)\n",
    "message = response['message']\n",
    "print(message['content'])\n",
    "messages.append(message)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "After analyzing the user stories in detail, here are my scores for each architecture pattern:\n",
      "\n",
      "**Layered Architecture**: 2\n",
      "The application has a clear separation of concerns between different roles (moderator, estimator, participant) and features (game management, estimation, user interface). However, some user stories suggest a need for flexibility and customization, which might not be easily achieved with a strict layered architecture. Additionally, the application's requirements are relatively complex, and a layered architecture might introduce performance overhead.\n",
      "\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 4\n",
      "Many user stories involve real-time updates and notifications, such as showing estimates immediately or displaying who gave what estimates during the current round. An event-driven architecture would be well-suited to handle these requirements, allowing for asynchronous processing and decoupling of components.\n",
      "\n",
      "**Microkernel Architecture**: 1\n",
      "The application's core functionality is relatively fixed, with a clear set of features and roles. There is no indication that the application needs to be highly customizable or extensible through plugins. Therefore, a microkernel architecture would not provide significant benefits in this case.\n",
      "\n",
      "**Microservices Architecture**: 3\n",
      "Some user stories suggest a need for scalability and flexibility, such as importing stories from a spreadsheet or exporting transcripts of games. A microservices architecture could help achieve these goals by breaking down the application into smaller, independently deployable services. However, the application's requirements are relatively cohesive, and a monolithic architecture might be sufficient.\n",
      "\n",
      "**Space-Based Architecture**: 1\n",
      "There is no indication that the application needs to handle high scalability or peak loads, which are typical use cases for space-based architectures. Additionally, the application's data model appears to be relatively simple, with no need for distributed memory or processing grids.\n",
      "\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "Some user stories involve sequential processing of data, such as estimating a story and then displaying all estimates immediately. A pipeline architecture would be well-suited to handle these requirements, allowing for modular and flexible processing of data.\n",
      "\n",
      "**Client-Server Architecture**: 3\n",
      "The application has a clear client-server structure, with moderators and estimators interacting with the server through web pages or URLs. However, some user stories suggest a need for real-time updates and notifications, which might not be easily achieved with a traditional client-server architecture.\n",
      "\n",
      "Here are the final scores:\n",
      "\n",
      "**Layered Architecture**: 2\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 4\n",
      "**Microkernel Architecture**: 1\n",
      "**Microservices Architecture**: 3\n",
      "**Space-Based Architecture**: 1\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "**Client-Server Architecture**: 3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Self-refinement Process"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "\n",
    "# Let's capture the model's initial answer in a variable:\n",
    "current_answer = message['content']  # e.g. the text with reasoning + final scores\n",
    "evaluator_context = messages.copy() # this context will be used in evaluator messages\n",
    "eval_system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are now the Evaluator. \n",
    "Your job: By taking the previously given user stories into account, review the given reasoning and scores for each architecture pattern by the user:\n",
    "\n",
    "Check for missing considerations, inconsistencies, or questionable logic. \n",
    "- If you see any potential refinements or additional considerations, list them clearly. Only suggest a refinement when you are sure there is a mistake with the given reasoning.\n",
    "\n",
    "After your refinement suggestions, on a NEW line, end your response with exactly one of the two markers:\n",
    "- REFINE (if improvements are needed)\n",
    "- NO_REFINEMENT (if no improvements are needed)\n",
    "\n",
    "Do not include any additional text after that marker.\n",
    "Do not wrap it in quotes.\n",
    "\n",
    "Important:\n",
    "- If you provide refinement for any of the pattern scores, do not use NO_REFINEMENT.\n",
    "Because this will stop the whole process and the current scores will be left unrefined.\n",
    "- Use NO_REFINEMENT if you have zero refinements to suggest.\n",
    "\"\"\"\n",
    "}\n",
    "evaluator_context.append(eval_system_message)\n",
    "\n",
    "refiner_context = messages.copy() # this context will be used in refiner messages\n",
    "\n",
    "refine_system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are now the Optimizer. \n",
    "You will be given your latest reasoning/scores and the evaluator's feedback for your latest reasoning/scores. \n",
    "Use it to revise the current scores. Keep the same format in the updated response (reasoning and then the updated scores).\n",
    "\"\"\"\n",
    "    }\n",
    "refiner_context.append(refine_system_message)\n",
    "# We'll define how many refinement loops to allow:\n",
    "MAX_REFINEMENT_ITERATIONS = 3\n",
    "\n",
    "refinement_iterations = MAX_REFINEMENT_ITERATIONS # if not set again in the loop, it means the model went through max iterations\n",
    "for i in range(MAX_REFINEMENT_ITERATIONS):\n",
    "    # 1) Evaluate the current answer\n",
    "    \n",
    "    evaluate_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "            Evaluate the given reasoning and scores by taking the original categorized user stories into account:\n",
    "\n",
    "            Current Answer:\n",
    "            {current_answer}\n",
    "\n",
    "            Revised Answer:\n",
    "            \"\"\"\n",
    "    }\n",
    "    evaluator_context.append(evaluate_prompt)\n",
    "    eval_response = client.chat(model=model_name, messages=evaluator_context)\n",
    "    eval_message = eval_response['message']\n",
    "    eval_feedback = eval_message['content'].strip()\n",
    "    evaluator_context.append(eval_message)\n",
    "    \n",
    "    print(f\"\\n=== Evaluator Feedback (Iteration {i+1}) ===\\n{eval_feedback}\\n\")\n",
    "    \n",
    "    # 2) If the evaluator indicates no changes are needed, break out\n",
    "    if \"NO_REFINEMENT\" in eval_feedback:\n",
    "        print(\"Evaluator says no changes are needed. Stopping refinement.\")\n",
    "        refinement_iterations = i\n",
    "        break\n",
    "    \n",
    "    # 3) Otherwise, refine\n",
    "    refine_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "            Refine your previous answer by taking the output of the evaluator into account. Keep the same format (reasoning and then the final scores).\n",
    "\n",
    "            Previous Answer:\n",
    "            {current_answer}\n",
    "\n",
    "            Evaluator Feedback:\n",
    "            {eval_feedback}\n",
    "\n",
    "            Revised Answer:\n",
    "            \"\"\"\n",
    "    }\n",
    "    refiner_context.append(refine_prompt)\n",
    "    \n",
    "    refine_response = client.chat(model=model_name, messages=refiner_context)\n",
    "    refine_message = refine_response['message']\n",
    "    revised_answer = refine_message['content'].strip()\n",
    "    refiner_context.append(refine_message)\n",
    "    \n",
    "    print(f\"=== Refined Answer (Iteration {i+1}) ===\\n{revised_answer}\\n\")\n",
    "    \n",
    "    # 4) Check if the refinement changed anything\n",
    "    if revised_answer == current_answer:\n",
    "        print(\"No substantial changes after refinement. Stopping.\")\n",
    "        break\n",
    "    \n",
    "    # Update current_answer for potential next iteration\n",
    "    current_answer = revised_answer\n",
    "\n",
    "# After the loop, current_answer holds the final refined output:\n",
    "print(\"=== Final Refined Scores & Reasoning ===\\n\", current_answer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Evaluator Feedback (Iteration 1) ===\n",
      "After re-evaluating the user stories, I have some refinements to suggest:\n",
      "\n",
      "* For **Layered Architecture**, I would score it as 1 instead of 2. While there is a clear separation of concerns between different roles and features, the application's requirements are quite complex, and a layered architecture might not be sufficient to handle all the necessary interactions and updates.\n",
      "* For **Event-Driven Architecture (Pub-Sub Architecture)**, I would score it as 5 instead of 4. The user stories suggest a high need for real-time updates and notifications, which is a perfect fit for an event-driven architecture. Additionally, the application's use cases involve multiple stakeholders interacting with each other in real-time, making this architecture even more suitable.\n",
      "* For **Microservices Architecture**, I would score it as 4 instead of 3. While the application's requirements are relatively cohesive, some user stories suggest a need for scalability and flexibility, which could be achieved through a microservices architecture. This would allow for independent deployment and scaling of services, making it easier to handle increased traffic or new features.\n",
      "* For **Space-Based Architecture**, I would score it as 2 instead of 1. While there is no indication that the application needs to handle high scalability or peak loads, some user stories suggest a need for efficient data processing and storage. A space-based architecture could be used to optimize data access and reduce latency, making it a more suitable choice than initially thought.\n",
      "\n",
      "Here are the revised scores:\n",
      "\n",
      "**Layered Architecture**: 1\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 5\n",
      "**Microkernel Architecture**: 1\n",
      "**Microservices Architecture**: 4\n",
      "**Space-Based Architecture**: 2\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "**Client-Server Architecture**: 3\n",
      "\n",
      "REFINE\n",
      "\n",
      "=== Refined Answer (Iteration 1) ===\n",
      "After re-evaluating the user stories and taking into account the evaluator's feedback, here is my revised answer:\n",
      "\n",
      "**Layered Architecture**: 1\n",
      "The application has a complex set of requirements that involve multiple stakeholders interacting with each other in real-time. A layered architecture might not be sufficient to handle all the necessary interactions and updates, making it less suitable for this project.\n",
      "\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 5\n",
      "The user stories suggest a high need for real-time updates and notifications, which is a perfect fit for an event-driven architecture. Additionally, the application's use cases involve multiple stakeholders interacting with each other in real-time, making this architecture even more suitable.\n",
      "\n",
      "**Microkernel Architecture**: 1\n",
      "The application's core functionality is relatively fixed, with a clear set of features and roles. There is no indication that the application needs to be highly customizable or extensible through plugins, making a microkernel architecture not beneficial for this project.\n",
      "\n",
      "**Microservices Architecture**: 4\n",
      "Some user stories suggest a need for scalability and flexibility, which could be achieved through a microservices architecture. This would allow for independent deployment and scaling of services, making it easier to handle increased traffic or new features.\n",
      "\n",
      "**Space-Based Architecture**: 2\n",
      "While there is no indication that the application needs to handle high scalability or peak loads, some user stories suggest a need for efficient data processing and storage. A space-based architecture could be used to optimize data access and reduce latency, making it a more suitable choice than initially thought.\n",
      "\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "Some user stories involve sequential processing of data, such as estimating a story and then displaying all estimates immediately. A pipeline architecture would be well-suited to handle these requirements, allowing for modular and flexible processing of data.\n",
      "\n",
      "**Client-Server Architecture**: 3\n",
      "The application has a clear client-server structure, with moderators and estimators interacting with the server through web pages or URLs. However, some user stories suggest a need for real-time updates and notifications, which might not be easily achieved with a traditional client-server architecture.\n",
      "\n",
      "Here are the final scores:\n",
      "\n",
      "**Layered Architecture**: 1\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 5\n",
      "**Microkernel Architecture**: 1\n",
      "**Microservices Architecture**: 4\n",
      "**Space-Based Architecture**: 2\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "**Client-Server Architecture**: 3\n",
      "\n",
      "\n",
      "=== Evaluator Feedback (Iteration 2) ===\n",
      "After re-evaluating the user stories and taking into account the revised answer, I have some additional refinements to suggest:\n",
      "\n",
      "* For **Event-Driven Architecture (Pub-Sub Architecture)**, I would score it as 5 is correct but the reasoning could be more detailed. The application's use cases involve multiple stakeholders interacting with each other in real-time, making this architecture even more suitable. However, it's worth noting that some user stories also suggest a need for efficient data processing and storage, which might require additional considerations when implementing an event-driven architecture.\n",
      "* For **Microservices Architecture**, I would score it as 4 is correct but the reasoning could be more detailed. Some user stories suggest a need for scalability and flexibility, which could be achieved through a microservices architecture. However, it's worth noting that some user stories also suggest a need for real-time updates and notifications, which might require additional considerations when implementing a microservices architecture.\n",
      "* For **Space-Based Architecture**, I would score it as 2 is correct but the reasoning could be more detailed. While there is no indication that the application needs to handle high scalability or peak loads, some user stories suggest a need for efficient data processing and storage. A space-based architecture could be used to optimize data access and reduce latency, making it a more suitable choice than initially thought.\n",
      "\n",
      "Here are the revised scores:\n",
      "\n",
      "**Layered Architecture**: 1\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 5\n",
      "**Microkernel Architecture**: 1\n",
      "**Microservices Architecture**: 4\n",
      "**Space-Based Architecture**: 2\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "**Client-Server Architecture**: 3\n",
      "\n",
      "REFINE\n",
      "\n",
      "=== Refined Answer (Iteration 2) ===\n",
      "After re-evaluating the user stories and taking into account the evaluator's feedback, here is my revised answer:\n",
      "\n",
      "**Layered Architecture**: 1\n",
      "The application has a complex set of requirements that involve multiple stakeholders interacting with each other in real-time. A layered architecture might not be sufficient to handle all the necessary interactions and updates, making it less suitable for this project.\n",
      "\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 5\n",
      "The user stories suggest a high need for real-time updates and notifications, which is a perfect fit for an event-driven architecture. Additionally, the application's use cases involve multiple stakeholders interacting with each other in real-time, making this architecture even more suitable. However, it's worth noting that some user stories also suggest a need for efficient data processing and storage, which might require additional considerations when implementing an event-driven architecture.\n",
      "\n",
      "**Microkernel Architecture**: 1\n",
      "The application's core functionality is relatively fixed, with a clear set of features and roles. There is no indication that the application needs to be highly customizable or extensible through plugins, making a microkernel architecture not beneficial for this project.\n",
      "\n",
      "**Microservices Architecture**: 4\n",
      "Some user stories suggest a need for scalability and flexibility, which could be achieved through a microservices architecture. This would allow for independent deployment and scaling of services, making it easier to handle increased traffic or new features. However, some user stories also suggest a need for real-time updates and notifications, which might require additional considerations when implementing a microservices architecture.\n",
      "\n",
      "**Space-Based Architecture**: 2\n",
      "While there is no indication that the application needs to handle high scalability or peak loads, some user stories suggest a need for efficient data processing and storage. A space-based architecture could be used to optimize data access and reduce latency, making it a more suitable choice than initially thought.\n",
      "\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "Some user stories involve sequential processing of data, such as estimating a story and then displaying all estimates immediately. A pipeline architecture would be well-suited to handle these requirements, allowing for modular and flexible processing of data.\n",
      "\n",
      "**Client-Server Architecture**: 3\n",
      "The application has a clear client-server structure, with moderators and estimators interacting with the server through web pages or URLs. However, some user stories suggest a need for real-time updates and notifications, which might not be easily achieved with a traditional client-server architecture.\n",
      "\n",
      "Here are the final scores:\n",
      "\n",
      "**Layered Architecture**: 1\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 5\n",
      "**Microkernel Architecture**: 1\n",
      "**Microservices Architecture**: 4\n",
      "**Space-Based Architecture**: 2\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "**Client-Server Architecture**: 3\n",
      "\n",
      "\n",
      "=== Evaluator Feedback (Iteration 3) ===\n",
      "NO_REFINEMENT\n",
      "\n",
      "Evaluator says no changes are needed. Stopping refinement.\n",
      "=== Final Refined Scores & Reasoning ===\n",
      " After re-evaluating the user stories and taking into account the evaluator's feedback, here is my revised answer:\n",
      "\n",
      "**Layered Architecture**: 1\n",
      "The application has a complex set of requirements that involve multiple stakeholders interacting with each other in real-time. A layered architecture might not be sufficient to handle all the necessary interactions and updates, making it less suitable for this project.\n",
      "\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 5\n",
      "The user stories suggest a high need for real-time updates and notifications, which is a perfect fit for an event-driven architecture. Additionally, the application's use cases involve multiple stakeholders interacting with each other in real-time, making this architecture even more suitable. However, it's worth noting that some user stories also suggest a need for efficient data processing and storage, which might require additional considerations when implementing an event-driven architecture.\n",
      "\n",
      "**Microkernel Architecture**: 1\n",
      "The application's core functionality is relatively fixed, with a clear set of features and roles. There is no indication that the application needs to be highly customizable or extensible through plugins, making a microkernel architecture not beneficial for this project.\n",
      "\n",
      "**Microservices Architecture**: 4\n",
      "Some user stories suggest a need for scalability and flexibility, which could be achieved through a microservices architecture. This would allow for independent deployment and scaling of services, making it easier to handle increased traffic or new features. However, some user stories also suggest a need for real-time updates and notifications, which might require additional considerations when implementing a microservices architecture.\n",
      "\n",
      "**Space-Based Architecture**: 2\n",
      "While there is no indication that the application needs to handle high scalability or peak loads, some user stories suggest a need for efficient data processing and storage. A space-based architecture could be used to optimize data access and reduce latency, making it a more suitable choice than initially thought.\n",
      "\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "Some user stories involve sequential processing of data, such as estimating a story and then displaying all estimates immediately. A pipeline architecture would be well-suited to handle these requirements, allowing for modular and flexible processing of data.\n",
      "\n",
      "**Client-Server Architecture**: 3\n",
      "The application has a clear client-server structure, with moderators and estimators interacting with the server through web pages or URLs. However, some user stories suggest a need for real-time updates and notifications, which might not be easily achieved with a traditional client-server architecture.\n",
      "\n",
      "Here are the final scores:\n",
      "\n",
      "**Layered Architecture**: 1\n",
      "**Event-Driven Architecture (Pub-Sub Architecture)**: 5\n",
      "**Microkernel Architecture**: 1\n",
      "**Microservices Architecture**: 4\n",
      "**Space-Based Architecture**: 2\n",
      "**Pipeline Architecture (Pipe-Filter Architecture)**: 4\n",
      "**Client-Server Architecture**: 3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summarize the evaluation result"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "refiner_context.append({'role': 'system', 'content': \"\"\"\n",
    "Ok now the evaluation process is finished. take the first assessment and the last assessment from the user. \n",
    "And just return the final scores before and after the evaluation-refinement process\n",
    "following this display format below:\n",
    "\n",
    "**Layered Architecture**: 1 -> 2\n",
    "**Event-Driven Architecture (Pub-Sub Architecture)**: 2 -> 2\n",
    "**Microkernel Architecture**: 3 -> 3\n",
    "**Microservices Architecture**: 4 -> 5\n",
    "**Space-Based Architecture**: 1 -> 3\n",
    "**Pipeline Architecture (Pipe-Filter Architecture)**: 2 -> 1\n",
    "**Client-Server Architecture**: 3 -> 3\n",
    "\"\"\"})\n",
    "\n",
    "refiner_context.append({'role': 'user', 'content': f\"\"\"\n",
    "read the first assessment and the last assessment, and return the final scores before and after the evaluation-refinement process\n",
    "following this display format below:\n",
    "\n",
    "**Layered Architecture**: 1 -> 2\n",
    "**Event-Driven Architecture (Pub-Sub Architecture)**: 2 -> 2\n",
    "**Microkernel Architecture**: 3 -> 3\n",
    "**Microservices Architecture**: 4 -> 5\n",
    "**Space-Based Architecture**: 1 -> 3\n",
    "**Pipeline Architecture (Pipe-Filter Architecture)**: 2 -> 1\n",
    "**Client-Server Architecture**: 3 -> 3\n",
    "\n",
    "\n",
    "first assessment:\n",
    "{refiner_context[2]}\n",
    "\n",
    "last assessment:\n",
    "{current_answer}\n",
    "\"\"\"})\n",
    "response = client.chat(model=model_name, messages=refiner_context)\n",
    "message = response['message']\n",
    "refiner_context.append(message)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Print log to output file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "final_data = {\n",
    "        \"modelName\": model_name,\n",
    "        \"modelParameters\": modelfile,\n",
    "        \"selfRefinement\": True,\n",
    "        \"oneShot\": False,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        \"lastMessage\": refiner_context[-1][\"content\"],\n",
    "        \"numberOfIterations\": refinement_iterations,\n",
    "        \"messages\": [message[\"content\"] for message in refiner_context],\n",
    "    }\n",
    "    \n",
    "# 3) Generate a filename based on model name and current timestamp\n",
    "filename = f\"./logs/self-refinement-zero-shot/log_{model_version}_{final_data['timestamp']}.json\"\n",
    "\n",
    "# 4) Write the conversation to a JSON file\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Assesment complete. The whole conversation is saved to {filename}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Assesment complete. The whole conversation is saved to log_llama3.1:8b-instruct-fp16_20250128_214127.json\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "interpreter": {
   "hash": "95ec9ec1504d83f612128e0fb229072f90bbb4cb09d9d5d93b5dd26e0ca2cfd1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}